---
title: "Item selection"
subtitle: "Erhebungsinstrument „Überzeugungen zum Verhältnis von Theorie und Praxis von Lehramtsstudierenden“"

author:
  - name: Jürgen Schneider 
    url: https://orcid.org/0000-0002-3772-4198
    affiliation: University of Tübingen
    affiliation_url: https://uni-tuebingen.de/de/28915
  - name: Ruben Kulcsar 
    url: http://wipaed.jku.at/wip-team/ruben-kulcsar/
    affiliation: University of Linz
    affiliation_url: http://wipaed.jku.at/wip-team/ruben-kulcsar/
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cosmo
    toc: yes
    toc_float:
      collapsed: false
    code_folding: hide
editor_options: 
  chunk_output_type: console
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=TRUE, 
  eval=TRUE,
  warning=FALSE,
  message=FALSE,
  tidy=TRUE,
  R.options=list(width=80),
  tidy.opts=list(width.cutoff=80), # For code
  width = 300,
  background="grey")  # For output
options(scipen=1, digits=3)
```

\
\
[![](../webs/osf0.png)](https://osf.io/jh6rx/)[&nbsp; Link to OSF-Project](https://osf.io/jh6rx/)
<br />
Questionnaire realized with [formr](https://formr.org/)
<br />
see the questionnaire [here](https://showcase.formr.org/)

\

# Data import & cleaning

**Import**
```{r data import, echo = T, cache=F}
library(tidyverse)
library(rio)
itemsel <- rio::import("https://raw.githubusercontent.com/j-5chneider/uzvvtp-las/master/data/pilot1.csv")
```


**Cleaning: delete empty rows/ rows of test run**  
data collection began at 28th Jan 2019: deleting all test runs before that date

```{r data cleaning 1, echo = T}
library(lubridate)

itemsel <- itemsel %>%
  filter(!is.na(ended)) %>%                   # delete empty cases
  mutate(ended = dmy_hm(ended)) %>%           # transform column into date format
  filter(ended > dmy("27-01-2019"))           # delete test runs before first data collection
```


# Sample description {.tabset}
and editing/deleting unreasonable values (e.g. out of range data)

## Semester

```{r data cleaning 2, echo = T}
# semester: no unreasonable values
ggplot(itemsel, aes(x = as.factor(semester))) +
  geom_bar() +
  labs(title = "Count of participants by semester",
       caption = "Note: There were no participants from third semester.") +
  geom_text(aes(label = ..count..), stat = "count", vjust = -0.3, size = 4)
```
\

## Standort

```{r data cleaning 3, echo = T}
# Standort: Two cases from Tübingen that checked Stuttgart
# However Stuttgart was not part of the sample and the time and date show the cases come from Tübingen
itemsel <- itemsel %>%
  mutate(standort = ifelse(standort == 4, 5, standort))

ggplot(itemsel, aes(x = factor(standort, labels = c("Flensburg", "Linz", "Tübingen", "Vechta")))) +
  geom_bar() +
  labs(title = "Count of participants by Standort") +
  geom_text(aes(label = ..count..), stat = "count", vjust = -0.3, size = 4)
```
\

## Subject

```{r data cleaning 4, echo = T}
library(knitr)
fach_freq <- data.frame(table(itemsel$fach))
names(fach_freq) <- c("Combination of Subjects", "Frequency")
kable(fach_freq, format = "html")
```

\

one person seemed to have checked nearly all subjects -> deletion of that value

```{r data cleaning 5, echo = T}
itemsel <- itemsel %>%
  mutate(fach = ifelse(fach == "1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 
                       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 
                       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 
                       52", NA, fach))

rm(fach_freq)
```

\

# item descriptions {.tabset}

## Question & answer format

* source: own creation
* question type: likert scale
* number of items: 68
* item question: "Bitte geben Sie an, wie stark die folgenden Aussagen über das Verhältnis von „Theorie“ und „Praxis“ Ihrer Meinung nach zutreffen!"
* value lables and numbers:
  + 1 = "stimme gar nicht zu"
  + 2 = ""
  + 3 = ""
  + 4 = ""
  + 5 = ""
  + 6 = "stimme voll zu"
* scales & subscales
  + Transfer
    + Transfer
    + Didaktik
  + Transformation
    + Transformation
    + Selektion
    + Enrichment
    + Adaption
  + Relationierung
    + Relationierung

## item labels and codes

```{r item names, layout = "l-screen-inset", echo = T}
# importing item labels and codes
items <- rio::import("https://raw.githubusercontent.com/j-5chneider/uzvvtp-las/master/data/items.csv")

library(kableExtra)

# table
items %>%
  kable() %>%
  column_spec(1:2, bold = T) %>%
  kableExtra::collapse_rows(columns = 1:2, valign = "middle") %>%
  row_spec(0, extra_css = "border-bottom: 2px solid #8F8F95") %>%
  row_spec(c(1:65), extra_css = "border-bottom: 1px solid #B9B8BC")
  
```

## descriptive item statistics

__item values__

```{r descriptives1, layout = "l-page", echo = T}
efa_data <- itemsel %>%
  dplyr::select("tfe_tfe_01":"rel_rel_09")

library(fBasics)
tmp_desc <-basicStats(efa_data)[c("Mean", "Stdev", "Median", "Minimum", "Maximum", "nobs", "NAs"),]


kable(tmp_desc, digits = 2) %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```
\
\


__density plots__

```{r descriptives2, layout = "l-screen-inset", echo = T, fig.width = 15, fig.height = 12}

efa_data_l <- gather(efa_data, key = "variable", value = "value", na.rm = T)

ggplot(efa_data_l, aes(x=value)) +
  facet_wrap(as.factor(efa_data_l$variable)) +
  stat_density(bw = 0.5)
```

\

# Results Study 1, FF1

## Number of factors 
Comparing number of factors via fit indices  
  
  
```{r nfactors1, layout="l-page", echo = T, fig.height = 6}
library(psych)

corMat <- cor(efa_data, use = "pairwise.complete.obs")
nfactors(x = corMat, n.obs = 219, rotate = "oblimin", fm = "mle", n = 12)
```
\
\


__Inference__  
Indices point to solutions between 3 and 6 factors.   
We will have a deeper look into these four different solutions, their consistency within factors and possible content interpretation via EFAs.
\
\

## Exploratory factor analyses {.tabset}

### 3 factor solution

```{r fa3.1, layout="l-page", echo = T}
# three factors with oblimin rotation and ML estimator
fa3  <- fa(r = corMat, nfactors = 3, n.obs = 219, rotate = "oblimin", fm = "ml")
fa.diagram(fa3)
```
\
\

__factors with ordered items ($\lambda$>.4) and item labels__

```{r fa3.2, layout="l-page", echo = T}
# preparing item data.frame
rownames(items) <- items$Code

items <- items %>%
  dplyr::select(`Item Label`)

# sort items according to factor and loading
fa3_tab <- fa.lookup(f = fa3, dictionary = items, cut = .4)

kable(fa3_tab) %>%
  row_spec(13:27, background = "#c4fdff") %>%
  scroll_box(width = "100%")

```


### 4 factor solution

```{r fa4.1, layout="l-page", echo = T}
# four factors with oblimin rotation and ML estimator
fa4  <- fa(r = corMat, nfactors = 4, n.obs = 219, rotate = "oblimin", fm = "ml")
fa.diagram(fa4)
```
\
\

__factors with ordered items ($\lambda$>.4) and item labels__

```{r fa4.2, layout="l-page", echo = T}
# sort items according to factor and loading
fa4_tab <- fa.lookup(f = fa4, dictionary = items, cut = .4)

kable(fa4_tab) %>%
  row_spec(17:24, background = "#c4fdff") %>%
  row_spec(20, background = "#ff9a9a") %>%
  row_spec(33:39, background = "#c4fdff") 

```

### 5 factor solution

```{r fa5.1, layout="l-page", echo = T}
# five factors with oblimin rotation and ML estimator
fa5  <- fa(r = corMat, nfactors = 5, n.obs = 219, rotate = "oblimin", fm = "ml")
fa.diagram(fa5)
```
\
\

__factors with ordered items ($\lambda$>.4) and item labels__

```{r fa5.2, layout="l-page", echo = T}
# sort items according to factor and loading
fa5_tab <- fa.lookup(f = fa5, dictionary = items, cut = .4)

kable(fa5_tab) %>%
  row_spec(10:16, background = "#c4fdff") %>%
  row_spec(23, background = "#ff9a9a") %>%
  row_spec(24:30, background = "#c4fdff")

```

### 6 factor solution

```{r fa6.1, layout="l-page", echo = T}
# six factors with oblimin rotation and ML estimator
fa6  <- fa(r = corMat, nfactors = 6, n.obs = 219, rotate = "oblimin", fm = "ml")
fa.diagram(fa6)
```
\
\

__factors with ordered items ($\lambda$>.4) and item labels__

```{r fa6.2, layout="l-page", echo = T}
# sort items according to factor and loading
fa6_tab <- fa.lookup(f = fa6, dictionary = items, cut = .4)

kable(fa6_tab) %>%
  row_spec(9:15, background = "#c4fdff") %>%
  row_spec(23:27, background = "#c4fdff") %>%
  row_spec(33:35, background = "#c4fdff") %>%
  row_spec(36, background = "#ff9a9a") %>%
  scroll_box(width = "100%")

```
\
\


# Reliability Analysis

Fit indices between the different factor solutions are quite similar. However, when consulting the items with highest loadings, the four factor solution

* allows clear interpretation of the factors itself (homogenity within factors)
* allows clear distinction of interpretation between factors (heterogenity between factors)


**4 Factor, McDonalds $\omega$**

```{r rel4, layout="l-page", echo = T}

# subsetting data for reliability analysis
rel_data4.1 <- efa_data %>%
  dplyr::select("tfe_tfe_03", "tfe_tfe_08", "tfe_did_01", "tfe_did_05", "tfe_tfe_02")    # 5 items with highest weights from transfer factor

rel_data4.2 <- efa_data %>%
  dplyr::select("tfo_sel_01", "tfo_sel_04", "tfo_sel_05", "tfo_sel_08", "tfo_sel_09")    # 5 items with highest weights from selection factor

rel_data4.3 <- efa_data %>%
  dplyr::select("tfo_enr_01", "tfo_enr_02", "tfo_enr_03", "tfo_enr_04", "tfo_enr_05")    # 5 items with highest weights from enrichment factor

rel_data4.4 <- efa_data %>%
  dplyr::select("rel_rel_02", "rel_rel_03", "rel_rel_08", "rel_rel_09")                  # 4 items with highest weights from relationierung factor 
                                                                                  # (with one negative and one transformation item deleted)

```

* __McDonalds__ $\sf{\omega_{Transfer}}$= `r MBESS::ci.reliability(rel_data4.1)$est`, __95%CI__[`r MBESS::ci.reliability(rel_data4.1)$ci.lower`, `r MBESS::ci.reliability(rel_data4.1)$ci.upper`]
* __McDonalds__ $\sf{\omega_{Selektion}}$= `r MBESS::ci.reliability(rel_data4.2)$est`, __95%CI__[`r MBESS::ci.reliability(rel_data4.2)$ci.lower`, `r MBESS::ci.reliability(rel_data4.2)$ci.upper`]
* __McDonalds__ $\sf{\omega_{Enrichment}}$= `r MBESS::ci.reliability(rel_data4.3)$est`, __95%CI__[`r MBESS::ci.reliability(rel_data4.3)$ci.lower`, `r MBESS::ci.reliability(rel_data4.3)$ci.upper`]
* __McDonalds__ $\sf{\omega_{Relationierung}}$= `r MBESS::ci.reliability(rel_data4.4)$est`, __95%CI__[`r MBESS::ci.reliability(rel_data4.4)$ci.lower`, `r MBESS::ci.reliability(rel_data4.4)$ci.upper`]


\
\

# Reformulation of several items

Several items of the instrument will be reformulated due to possible two-dimensionality (that can be further avoided): E.g. the item "Wissenschaftliches Wissen wird durch Lehrer*innen unmittelbar auf praktisches Handeln in der Schule übertragen." asks (1) if there is a __possibility__ of transfer and (2) if teachers __actually__ perform transformations (an empirical question). We decided to lose the empirical side of the question as we are interested in the perceived possibilities.  
\

In column "itemlabel_re", deleted words are marked by strikethrough, newly added words are italicised.  
New item labels can be found in the column "itemlabel".

```{r items reformulate, layout="l-page", echo = T, cache=F}
items_4f <- read.csv("https://raw.githubusercontent.com/j-5chneider/uzvvtp-las/master/data/items_4f.csv", sep = ";")

kable(items_4f) %>%
  row_spec(6:10, background = "#c4fdff") %>%
  row_spec(16:19, background = "#c4fdff") %>%
  collapse_rows(columns = 1, valign = "middle") %>%
  scroll_box(width = "100%")
```


\
\

# Used packages & Setup

```{r}
installed.packages()[names(sessionInfo()$otherPkgs), "Version"]
R.Version()
```

